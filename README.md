# semantic_simulator
Synthetic Semantic Dataset Generator (SSDG)


## Description
![](/imgs/sample.png)

Synthetic Semantic Dataset Generator (SSDG) uses a segmentation camera and Lidar to create a labelled point cloud of 3D models in a a gazebo simulation. By using the segmentation cameras mounted on the robot, each point generated by the LiDAR is given a semantic label by projecting the 3D cloud onto the 2D image plane. The 2D image from the segmentation cameras contains a label map which is used to give each pixel a semantic value, and can thus be used to give corresponding points from the cloud its correct semantic label.
The software consists of three modules:
- Labelling node, responsible for labelling the point cloud using the segmentation cameras label map
- Collision avoidance node, found in 'lidar_node.cc'



## Build and Installation
We have included an example world to give an overview of the simulation

1. For building the collision avoidance node:
```
mkdir build
cd build
cmake ..
make 
./lidar_node
```
2. Labelling node
The labelling node folder must be placed in your catkin workspace for use. It can be used separately by running
```
source ~/workspace/devel/setup.bash
rosrun labelling_node listener.py
```

## Run
```
source ~/workspace/devel/setup.bash
roslaunch launch/segmentation.launch directory:=/path/to/your/directory
```
or 
```
roslaunch launch/multi_object.launch directory:=/path/to/your/directory
```



### References

for questions, contact:
Marius Udn√¶s, mariusudnaes@gmail.com